{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae6c95c5-88fd-464a-af44-dd6d65407d54",
     "showTitle": false,
     "tableResultSettingsMap": {
      "2": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"#row_number#\":135},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1757892921209}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 2
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # 05 - KPI Report: Evaluaci√≥n y Visualizaci√≥n\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# IMPORTACIONES\n",
    "from pyspark.sql.functions import col, count, when, isnan\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import joblib\n",
    "\n",
    "# CONFIGURACI√ìN DE GR√ÅFICAS\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# üìå Cargar tabla original y tabla limpia\n",
    "df_raw = spark.table(\"datalottery.lotterybets.lottery_bets_dirty\")\n",
    "df_clean = spark.table(\"datalottery.lotterybets.lottery_bets_dirty_cleaned\")\n",
    "\n",
    "print(f\"üìä Registros originales: {df_raw.count()}\")\n",
    "print(f\"üìà Registros luego de limpieza: {df_clean.count()}\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# üîç Calcular nulos por columna en raw\n",
    "from pyspark.sql.types import NumericType\n",
    "\n",
    "# Separar columnas num√©ricas y no num√©ricas\n",
    "numeric_cols = [f.name for f in df_raw.schema.fields if isinstance(f.dataType, NumericType)]\n",
    "non_numeric_cols = [f.name for f in df_raw.schema.fields if not isinstance(f.dataType, NumericType)]\n",
    "\n",
    "# Contar nulos en num√©ricas (isNull + isnan)\n",
    "nulos_numeric = df_raw.select([\n",
    "    count(when(col(c).isNull() | isnan(col(c)), c)).alias(c)\n",
    "    for c in numeric_cols\n",
    "])\n",
    "\n",
    "# Contar nulos en no num√©ricas (solo isNull)\n",
    "nulos_non_numeric = df_raw.select([\n",
    "    count(when(col(c).isNull(), c)).alias(c)\n",
    "    for c in non_numeric_cols\n",
    "])\n",
    "\n",
    "# Unir y convertir a Pandas\n",
    "nulos_raw = nulos_numeric.join(nulos_non_numeric).toPandas().T.rename(columns={0: 'nulos_raw'})\n",
    "\n",
    "# üîç Calcular nulos por columna en clean\n",
    "from pyspark.sql.types import NumericType\n",
    "\n",
    "# Separar columnas num√©ricas y no num√©ricas\n",
    "numeric_cols_clean = [f.name for f in df_clean.schema.fields if isinstance(f.dataType, NumericType)]\n",
    "non_numeric_cols_clean = [f.name for f in df_clean.schema.fields if not isinstance(f.dataType, NumericType)]\n",
    "\n",
    "# Contar nulos en num√©ricas (isNull + isnan)\n",
    "nulos_numeric_clean = df_clean.select([\n",
    "    count(when(col(c).isNull() | isnan(col(c)), c)).alias(c)\n",
    "    for c in numeric_cols_clean\n",
    "])\n",
    "\n",
    "# Contar nulos en no num√©ricas (solo isNull)\n",
    "nulos_non_numeric_clean = df_clean.select([\n",
    "    count(when(col(c).isNull(), c)).alias(c)\n",
    "    for c in non_numeric_cols_clean\n",
    "])\n",
    "\n",
    "# Unir y convertir a Pandas\n",
    "nulos_clean = nulos_numeric_clean.join(nulos_non_numeric_clean).toPandas().T.rename(columns={0: 'nulos_clean'})\n",
    "\n",
    "# Unir y mostrar\n",
    "nulos_comparativo = pd.concat([nulos_raw, nulos_clean], axis=1)\n",
    "nulos_comparativo[\"% reducci√≥n\"] = (\n",
    "    100 * (nulos_comparativo[\"nulos_raw\"] - nulos_comparativo[\"nulos_clean\"]) / nulos_comparativo[\"nulos_raw\"].replace(0, 1)\n",
    ")\n",
    "display(nulos_comparativo)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# üìä Gr√°fico: Comparativa de nulos por columna\n",
    "nulos_comparativo_plot = nulos_comparativo.reset_index().rename(columns={\"index\": \"columna\"})\n",
    "nulos_comparativo_plot = nulos_comparativo_plot[nulos_comparativo_plot[\"nulos_raw\"] > 0]\n",
    "\n",
    "plt.figure()\n",
    "sns.barplot(data=nulos_comparativo_plot, x=\"columna\", y=\"nulos_raw\", color=\"red\", label=\"Antes\")\n",
    "sns.barplot(data=nulos_comparativo_plot, x=\"columna\", y=\"nulos_clean\", color=\"green\", label=\"Despu√©s\")\n",
    "plt.title(\"Comparaci√≥n de valores nulos antes vs despu√©s de limpieza\")\n",
    "plt.ylabel(\"N¬∫ de valores nulos\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# COMMAND ----------datalottery.lotterybets.lottery_bets_dirty\n",
    "\n",
    "# üìä Ver versiones de tabla Delta (Time Travel)\n",
    "history_df = spark.sql(\"DESCRIBE HISTORY datalottery.lotterybets.lottery_bets_dirty_cleaned\")\n",
    "display(history_df.select(\"version\", \"timestamp\", \"operation\", \"operationMetrics\"))\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# üìå Verificaci√≥n: Tabla de features y modelo\n",
    "df_features = spark.table(\"datalottery.lotterybets.lottery_bets_dirty_features\")\n",
    "print(f\"‚úÖ Features cargadas: {df_features.count()} registros\")\n",
    "\n",
    "# Convertir a pandas\n",
    "df_pd = df_features.select(\n",
    "    \"bets_last_7d\", \"win_rate_last_30d\", \"ip_risk\", \"geo_risk\", \n",
    "    \"num_picks\", \"avg_stake_amount\", \"suspicious\"\n",
    ").toPandas()\n",
    "\n",
    "# Separar X, y\n",
    "X = df_pd.drop(columns=[\"suspicious\"])\n",
    "y = df_pd[\"suspicious\"]\n",
    "\n",
    "# Intentar cargar el modelo\n",
    "try:\n",
    "    model = joblib.load(\"/tmp/ProyectoMLOps_rf_model.joblib\")\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "    auc = roc_auc_score(y, y_pred)\n",
    "    print(f\"üéØ AUC del modelo actual: {auc:.3f}\")\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è No se pudo cargar el modelo. Error:\", e)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# üìà Gr√°fico: Distribuci√≥n de variable objetivo\n",
    "# Preparar DataFrame para gr√°fico barras lado a lado\n",
    "nulos_comparativo_plot = nulos_comparativo.reset_index().rename(columns={\"index\": \"columna\"})\n",
    "nulos_comparativo_plot = nulos_comparativo_plot[nulos_comparativo_plot[\"nulos_raw\"] > 0]\n",
    "\n",
    "# Convertir a formato largo\n",
    "df_long = nulos_comparativo_plot.melt(\n",
    "    id_vars='columna',\n",
    "    value_vars=['nulos_raw', 'nulos_clean'],\n",
    "    var_name='Estado',\n",
    "    value_name='Nulos'\n",
    ")\n",
    "\n",
    "# Mapear nombres para leyenda\n",
    "df_long['Estado'] = df_long['Estado'].map({'nulos_raw': 'Antes', 'nulos_clean': 'Despu√©s'})\n",
    "\n",
    "# Graficar barras lado a lado con hue\n",
    "plt.figure()\n",
    "sns.barplot(data=df_long, x='columna', y='Nulos', hue='Estado')\n",
    "plt.title(\"Comparaci√≥n de valores nulos antes vs despu√©s de limpieza\")\n",
    "plt.ylabel(\"N¬∫ de valores nulos\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# üéØ KPI final resumen (puedes imprimir o exportar)\n",
    "\n",
    "kpis = {\n",
    "    \"Registros originales\": str(df_raw.count()),\n",
    "    \"Registros luego de limpieza\": str(df_clean.count()),\n",
    "    \"Duplicados eliminados\": str(df_raw.count() - df_clean.count()),\n",
    "    \"AUC del modelo (si carg√≥)\": f\"{auc:.3f}\" if 'auc' in locals() else \"N/A\",\n",
    "    \"Columnas con nulos antes\": str(int((nulos_comparativo[\"nulos_raw\"] > 0).sum())),\n",
    "    \"Columnas con nulos despu√©s\": str(int((nulos_comparativo[\"nulos_clean\"] > 0).sum())),\n",
    "    \"Reducci√≥n total de nulos\": str(int(nulos_comparativo[\"nulos_raw\"].sum() - nulos_comparativo[\"nulos_clean\"].sum())),\n",
    "    \"Versiones de la tabla Delta\": str(history_df.count())\n",
    "}\n",
    "\n",
    "kpis_df = pd.DataFrame.from_dict(kpis, orient=\"index\", columns=[\"Valor\"])\n",
    "display(kpis_df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05_KPI_Report",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
